<!-- File: readme.html

  Copyright (c) 2023 Splunk Inc.

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  {% comment %} You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software distributed under
  the License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
  either express or implied. See the License for   and limitations under the License.
-->

<h3>
    The Splunk Attack Analyzer SOAR app can be used to connect with the
    <a target="_blank" href='https://app.twinwave.io/'>
        Splunk Attack Analyzer analysis platform
    </a>
</h3>
<p>
    <ul>Common points for both Manual and Scheduled | Interval polling:</ul>
    <li>The on poll action fetches and ingests the done/completed jobs in the form of artifacts and containers.</li>
    <li>One container will be created for each job and the artifacts will have information about the resources present in the particular job, hence for every resource present, one artifact will be created.</li>
    <li>In case of duplicate data, containers would not be created again.</li>

    <ul>Manual Polling:</ul>
    <li>During manual polling, the app starts ingestion from the time specified in the since configuration parameter. </li>
    <li>If 2 hours is specified in the since parameter, for every cycle jobs of the last 2 hours will be fetched and ingested. If no value is specified, by default jobs of the last 24 hours will be ingested.</li>
    <li>The app will fetch the number of jobs based on the value provided in the Maximum containers(container_count) for manual polling</li>
    <li>For manual polling, the time of the last ingested job will not be stored in the state file, and for every cycle all the jobs from the time mentioned in the since parameter will be fetched.</li>

    <ul>Schedule | Interval Polling:</ul>
    <li>For the first run of scheduled | interval polling, the app starts ingestion from the time specified in the since configuration parameter.</li>
    <li>If 2 hours is specified in the since parameter, for the first run all the jobs of the last 2 hours will be fetched, and if no value is specified, by default jobs of the last 24 hours will be ingested for the first run.</li>
    <li>After the completion of every run, the 'UpdatedAt' time of the latest job will be stored in the state file against the key "UpdatedAt_Checkpoint" and for the next run, that time will be considered to fetch the data. Hence from the second run onwards, the jobs will be fetched from the time stored in the state file instead of the value given in the since parameter.</li>
</p>
<p>
    The following actions are supported by the app:
        <ul>
            <li>Submitting a URL for analysis</li>
            <li>Submitting a file for analysis</li>
            <li>Fetching analysis (job) summary data</li>
            <li>Fetching the forensics for a job</li>
            <li>Downloading screenshots for a job and attaching them to the vault</li>
            <li>Downloading an offline PDF report for a job and attaching it to the vault</li>
            <li>Fetching list of recently submitted jobs</li>
        </ul>
</p>
